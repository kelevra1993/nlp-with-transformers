{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d42ef8-82cf-4d3f-8e3b-a873487f280e",
   "metadata": {},
   "source": [
    "# Notes For Future Investigations\n",
    "\n",
    "## Chapter 1\n",
    "1. Use the twitter dataset of emotion classification in order to test hypothesis that work or do not work.\n",
    "\n",
    "## Chapter 2\n",
    "1.  Test out the ablation of some questionable added Dropouts, especially the one added in the initial embeddings\n",
    "2.  Test positions of layer normalization layers\n",
    "3.  Test adding layer normalization both before and after MHA and FF layer\n",
    "4.  Test different positional embeddings\n",
    "    1. Classic embeddings proposed in chapter 2\n",
    "    2. Test binary code embedding accompanied by learnable embedding weight matrix\n",
    "       1. Add the positional embedding\n",
    "       2. Concatenate the positional embedding\n",
    "5.  Test adding objective tasks for Natural Language Understanding, such as :\n",
    "    1. Masked Language Modelling.\n",
    "    2. Translation Language Modelling.\n",
    "    3. Sentence Ordering Prediction.\n",
    "    4. Pre-training the text encoders as Discriminators (ELECTRA architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f788b-1daa-47c4-82c5-b458656eda57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_with_transformers",
   "language": "python",
   "name": "nlp_with_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
